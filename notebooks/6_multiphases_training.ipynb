{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def available_gpus():\n",
    "    gpus = torch.cuda.device_count()\n",
    "    return [torch.cuda.get_device_name(i) for i in range(gpus)]\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"GPUs disponibles:\", available_gpus())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from datetime import datetime\n",
    "from libraries.utils import read_csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from dateutil.relativedelta import relativedelta\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from esa_libraries.ESAScores import ESAScores\n",
    "from metrics_libraries.basic_methods import precision_corrected_score, recall_score, f05_score\n",
    "\n",
    "from models_architectures.AutoEnconderFullWindow import AutoEnconderFullWindow\n",
    "from models_architectures.AutoEnconderLastEvent import AutoEnconderLastEvent\n",
    "from models_architectures.VariationalAutoencoderFullWindow import VariationalAutoencoderFullWindow\n",
    "from models_architectures.VariationalAutoencoderLastEvent import VariationalAutoencoderLastEvent\n",
    "from libraries.sequence_generators import sequence_generator, sequence_generator_last_event"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MISSION = 2\n",
    "\n",
    "WINDOW_SIZE = 50\n",
    "PERCENTILE = 99\n",
    "BATCH_SIZE = 256\n",
    "EPOCHS = 25\n",
    "LEARNING_RATE = 0.0001\n",
    "\n",
    "CHANNELS = [\"allchannels\", \"subset\", \"target\"][2]\n",
    "\n",
    "START_DATE = pd.to_datetime(\"2000-01-01\")\n",
    "END_DATE = pd.to_datetime(\"2014-01-01\") if MISSION == 1 else pd.to_datetime(\"2003-07-01\")\n",
    "\n",
    "MONTHS_TO_TRAIN = 6\n",
    "MONTHS_TO_TEST = 1\n",
    "MODEL_TYPE = [\"AutoEncoderFullWindow\",\n",
    "              \"AutoEncoderLastEvent\",\n",
    "              \"VariationalAutoencoderFullWindow\",\n",
    "              \"VariationalAutoencoderLastEvent\"][3]\n",
    "\n",
    "CHANNELS_INFO_PATH = f\"../data/Mission{MISSION}-ESA/channels.csv\"\n",
    "ESA_ANOMALIES_PATH = f\"../esa-anomalies/anomalies_mission{MISSION}.csv\"\n",
    "\n",
    "timestamp = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\").replace(\" \", \"_\").replace(\":\", \"-\")\n",
    "EXPERIMENT_NAME = f\"Mission{MISSION}_{CHANNELS}_{MODEL_TYPE}_{START_DATE.strftime('%Y-%m-%d')}_{END_DATE.strftime('%Y-%m-%d')}_T{MONTHS_TO_TRAIN}_V{MONTHS_TO_TEST}_window{WINDOW_SIZE}_percentile{PERCENTILE}_epochs{EPOCHS}_lr{LEARNING_RATE}__{timestamp}\"\n",
    "RESULT_PATH = f\"../metrics/multiphases_training/{EXPERIMENT_NAME}.csv\"\n",
    "EXPERIMENT_NAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_channel_number = 41 if MISSION == 1 else 18  # Only if CHANNELS == \"subset\" \n",
    "last_channel_number = 46 if MISSION == 1 else 28  # Only if CHANNELS == \"subset\"\n",
    "\n",
    "if CHANNELS == \"subset\":\n",
    "    input_data_path = f'../data/Mission{MISSION}-Preprocessed/data_preprocessed_channels{first_channel_number}_{last_channel_number}_frequency-previous_2000_{2013 if MISSION == 1 else 2003}.csv'\n",
    "else:\n",
    "    input_data_path = f'../data/Mission{MISSION}-Preprocessed/data_preprocessed_{CHANNELS}_frequency-previous_2000_{2013 if MISSION == 1 else 2003}.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "if CHANNELS == \"target\":\n",
    "    channels_info = pd.read_csv(CHANNELS_INFO_PATH)\n",
    "    channels_list = list(channels_info[channels_info['Target']==\"YES\"]['Channel'])\n",
    "else:\n",
    "    channels_list = None if CHANNELS == \"allchannels\" else [f\"channel_{i}\" for i in range(first_channel_number, last_channel_number+1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = read_csv(input_data_path, sep=\";\")\n",
    "if channels_list is not None:\n",
    "    data = data[channels_list]\n",
    "\n",
    "# Filtrar los datos entre start_date_train y end_date_train\n",
    "data = data.loc[(data.index >= START_DATE) & (data.index < END_DATE)]\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "esa_anomalies = pd.read_csv(ESA_ANOMALIES_PATH)\n",
    "esa_anomalies['StartTime'] = pd.to_datetime(esa_anomalies['StartTime'], errors='coerce').dt.tz_localize(None)\n",
    "esa_anomalies['EndTime'] = pd.to_datetime(esa_anomalies['EndTime'], errors='coerce').dt.tz_localize(None)\n",
    "esa_anomalies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sum_months_to_date(date, months):\n",
    "    return date + relativedelta(months=months)\n",
    "\n",
    "def calculate_period_months(start_date, end_date):\n",
    "    difference = relativedelta(end_date, start_date)\n",
    "    return difference.years * 12 + difference.months"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(data_dict, input_path, channels, start_date_val, end_date_val, sep=';'):\n",
    "    def _get_years(start_date_val, end_date_val):\n",
    "        adjusted_end_date = end_date_val - relativedelta(days=1)\n",
    "        return list(range(start_date_val.year, adjusted_end_date.year + 1))\n",
    "    \n",
    "    years = _get_years(start_date_val, end_date_val)\n",
    "    result_data_dict = {k: v for k, v in data_dict.items() if k in years}\n",
    "    for year in years:\n",
    "        if year not in result_data_dict.keys():\n",
    "            input_full_path = f\"{input_path}{year}.csv\"\n",
    "            df = read_csv(input_full_path, sep=sep)\n",
    "            if channels is not None:\n",
    "                df = df[channels]\n",
    "            result_data_dict[year] = df\n",
    "    \n",
    "    dfs = []\n",
    "    for year in years:\n",
    "        df = result_data_dict[year]\n",
    "        dfs.append(df[(start_date_val <= df.index) & (df.index <= end_date_val)].copy())\n",
    "    result_df = pd.concat(dfs, ignore_index=False)  \n",
    "    return result_df, result_data_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def format_anomalies(anomalies: pd.DataFrame) -> pd.DataFrame:\n",
    "    formatted_data = []\n",
    "\n",
    "    # Iterar sobre cada canal (columna)\n",
    "    for channel in anomalies.columns:\n",
    "        channel_data = anomalies[channel]\n",
    "        is_active = False  # Para rastrear si estamos dentro de una secuencia activa\n",
    "        start_time = None  # Almacenar el tiempo de inicio de la anomalía\n",
    "\n",
    "        # Iterar por cada fila en el canal\n",
    "        for time, value in channel_data.items():\n",
    "            if value == 1 and not is_active:\n",
    "                # Detectamos el inicio de una anomalía\n",
    "                is_active = True\n",
    "                start_time = time\n",
    "            elif value == 0 and is_active:\n",
    "                # Detectamos el final de una anomalía\n",
    "                is_active = False\n",
    "                end_time = time\n",
    "                # Guardar el resultado\n",
    "                formatted_data.append({\"Channel\": channel, \"StartTime\": start_time, \"EndTime\": end_time})\n",
    "\n",
    "        # Manejar el caso en que una anomalía sigue activa hasta el final del DataFrame\n",
    "        if is_active:\n",
    "            formatted_data.append({\"Channel\": channel, \"StartTime\": start_time, \"EndTime\": channel_data.index[-1]})\n",
    "\n",
    "    # Convertir los resultados en un nuevo DataFrame\n",
    "    anomalies_formatted = pd.DataFrame(formatted_data)\n",
    "\n",
    "    # Ordenar el DataFrame por StartTime\n",
    "    anomalies_formatted = anomalies_formatted.sort_values(by=\"StartTime\").reset_index(drop=True)\n",
    "\n",
    "    return anomalies_formatted\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_esa_anomalies(esa_anomalies, start_date, end_date):\n",
    "    # Filter by date\n",
    "    esa_anomalies_filtered = esa_anomalies[(esa_anomalies[\"EndTime\"] >= start_date) & (esa_anomalies[\"StartTime\"] <= end_date)]\n",
    "    esa_anomalies_filtered.loc[esa_anomalies_filtered['StartTime'] < start_date, 'StartTime'] = start_date\n",
    "    esa_anomalies_filtered.loc[esa_anomalies_filtered['EndTime'] > end_date, 'EndTime'] = end_date\n",
    "    esa_anomalies_filtered.reset_index(drop=True, inplace=True)\n",
    "    return esa_anomalies_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_anomalies_list(anomalies_df):\n",
    "    # Genera una lista donde sus elementos son listas de dos elementos con el timestampt y 0 si todos los valores de la fila es 0 y 1 si alguno es 1\n",
    "    anomalies_list = []\n",
    "    for index, row in anomalies_df.iterrows():\n",
    "        if row.any():\n",
    "            anomalies_list.append([index, 1])\n",
    "        else:\n",
    "            anomalies_list.append([index, 0])\n",
    "    return anomalies_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models training methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_autoencoder(train_generator, val_generator, model, criterion, optimizer, epochs, steps_per_epoch_train, steps_per_epoch_val, device):\n",
    "    train_loss_history = []\n",
    "    val_loss_history = []\n",
    "\n",
    "    model.train()\n",
    "    # for epoch in range(epochs):\n",
    "    for epoch in tqdm(range(epochs), desc=\"Training model\"):\n",
    "        total_train_loss = 0  # Initialize total training loss for the epoch\n",
    "\n",
    "        # Training loop\n",
    "        for step in range(steps_per_epoch_train):\n",
    "            inputs, targets = next(train_generator)\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_train_loss += loss.item()  # Accumulate training loss\n",
    "\n",
    "        avg_train_loss = total_train_loss / steps_per_epoch_train  # Calculate average training loss\n",
    "        train_loss_history.append(avg_train_loss)\n",
    "\n",
    "        # Validation loop (if val_generator is provided)\n",
    "        if val_generator is not None:\n",
    "            model.eval()  # Set the model to evaluation mode\n",
    "            total_val_loss = 0\n",
    "\n",
    "            with torch.no_grad():\n",
    "                for step in range(steps_per_epoch_val):\n",
    "                    val_inputs, val_targets = next(val_generator)\n",
    "                    val_inputs, val_targets = inputs.to(device), targets.to(device)\n",
    "\n",
    "                    val_outputs = model(val_inputs)\n",
    "                    val_loss = criterion(val_outputs, val_targets)\n",
    "\n",
    "                    total_val_loss += val_loss.item()\n",
    "\n",
    "            avg_val_loss = total_val_loss / steps_per_epoch_val  # Calculate average validation loss\n",
    "            val_loss_history.append(avg_val_loss)\n",
    "            # print(f\"Epoch [{epoch + 1}/{epochs}], Train Loss: {avg_train_loss:.4f}, Val Loss: {avg_val_loss:.4f}\")\n",
    "        else:\n",
    "            # print(f\"Epoch [{epoch + 1}/{epochs}], Train Loss: {avg_train_loss:.4f}\")\n",
    "            pass\n",
    "\n",
    "    return train_loss_history, val_loss_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_vae(train_generator, val_generator, model, criterion, optimizer, epochs, steps_per_epoch_train, steps_per_epoch_val, device):\n",
    "    train_loss_history = []\n",
    "    val_loss_history = []\n",
    "\n",
    "    model.train()\n",
    "    # for epoch in range(epochs):\n",
    "    for epoch in tqdm(range(epochs), desc=\"Training model\"):\n",
    "        total_train_loss = 0  # Initialize total training loss for the epoch\n",
    "\n",
    "        # Training loop\n",
    "        for step in range(steps_per_epoch_train):\n",
    "            inputs, targets = next(train_generator)\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            reconstructed, mu, logvar = model(inputs)\n",
    "            loss = criterion(reconstructed, targets, mu, logvar)\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_train_loss += loss.item()  # Accumulate training loss\n",
    "\n",
    "        avg_train_loss = total_train_loss / steps_per_epoch_train  # Calculate average training loss\n",
    "        train_loss_history.append(avg_train_loss)\n",
    "\n",
    "        # Validation loop (if val_generator is provided)\n",
    "        if val_generator is not None:\n",
    "            model.eval()  # Set the model to evaluation mode\n",
    "            total_val_loss = 0\n",
    "\n",
    "            with torch.no_grad():\n",
    "                for step in range(steps_per_epoch_val):\n",
    "                    val_inputs, val_targets = next(val_generator)\n",
    "                    val_inputs, val_targets = inputs.to(device), targets.to(device)\n",
    "\n",
    "                    val_reconstructed, val_mu, val_logvar = model(val_inputs)\n",
    "                    val_loss = criterion(val_reconstructed, val_targets, val_mu, val_logvar)\n",
    "\n",
    "                    total_val_loss += val_loss.item()\n",
    "\n",
    "            avg_val_loss = total_val_loss / steps_per_epoch_val  # Calculate average validation loss\n",
    "            val_loss_history.append(avg_val_loss)\n",
    "            # print(f\"Epoch [{epoch + 1}/{epochs}], Train Loss: {avg_train_loss:.4f}, Val Loss: {avg_val_loss:.4f}\")\n",
    "        else:\n",
    "            # print(f\"Epoch [{epoch + 1}/{epochs}], Train Loss: {avg_train_loss:.4f}\")\n",
    "            pass\n",
    "\n",
    "    return train_loss_history, val_loss_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vae_loss_function(reconstructed, target, mu, logvar):\n",
    "    # Error de reconstrucción (MSE o BCE según el caso)\n",
    "    reconstruction_loss = nn.MSELoss()(reconstructed, target)\n",
    "\n",
    "    # KL-divergence\n",
    "    kl_loss = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "\n",
    "    # Loss total\n",
    "    return reconstruction_loss + kl_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model_type, train_df_normalized, epochs, window_size, batch_size, learning_rate, device):\n",
    "    steps_per_epoch_train = (len(train_df_normalized) - window_size) // batch_size\n",
    "    if model_type == \"AutoEncoderFullWindow\" or model_type == \"AutoEncoderLastEvent\":\n",
    "        if model_type == \"AutoEncoderFullWindow\":\n",
    "            model = AutoEnconderFullWindow(window_size, train_df_normalized.shape[1], latent_dim=8).to(device)\n",
    "            train_gen = sequence_generator(train_df_normalized.values, window_size, batch_size)\n",
    "        else:\n",
    "            model = AutoEnconderLastEvent(window_size, train_df_normalized.shape[1], latent_dim=8).to(device)\n",
    "            train_gen = sequence_generator_last_event(train_df_normalized.values, window_size, batch_size)\n",
    "\n",
    "        criterion = nn.MSELoss()\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "        _, _ = train_autoencoder(train_gen, None, model, criterion, optimizer, epochs=epochs,\n",
    "                  steps_per_epoch_train=steps_per_epoch_train, steps_per_epoch_val=None, device=device)\n",
    "        return model\n",
    "    \n",
    "    else:\n",
    "        if model_type == \"VariationalAutoencoderFullWindow\":\n",
    "            model = VariationalAutoencoderFullWindow(window_size, train_df_normalized.shape[1], latent_dim=8).to(device)\n",
    "            train_gen = sequence_generator(train_df_normalized.values, window_size, batch_size)\n",
    "        else:\n",
    "            model = VariationalAutoencoderLastEvent(window_size, train_df_normalized.shape[1], latent_dim=8).to(device)\n",
    "            train_gen = sequence_generator_last_event(train_df_normalized.values, window_size, batch_size)\n",
    "        criterion = vae_loss_function\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "        _, _ = train_vae(train_gen, None, model, criterion, optimizer, epochs=epochs,\n",
    "                  steps_per_epoch_train=steps_per_epoch_train, steps_per_epoch_val=None, device=device)\n",
    "        return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Threshold methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def anomaly_limits(errors, percentile, axis) -> float:\n",
    "    P1 = np.percentile(errors, 100-percentile, axis)\n",
    "    P2 = np.percentile(errors, percentile, axis)\n",
    "    IPR = P2 - P1\n",
    "    return list(P2 + 1.5 * IPR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_channels_thresholds_autoencoder_full(percentile, autoencoder, df_normalized, window_size, batch_size, device):\n",
    "    steps_per_epoch = (len(df_normalized) - window_size) // batch_size\n",
    "\n",
    "    # Umbral basado en el percentil 95 del error\n",
    "    train_gen = sequence_generator(df_normalized.values, window_size, batch_size)\n",
    "    reconstruction_errors = []\n",
    "\n",
    "    # Barra de progreso para el cálculo de reconstruction_errors\n",
    "    for _ in tqdm(range(steps_per_epoch), desc=\"Calculando errores de reconstrucción\"):\n",
    "        batch, _ = next(train_gen)  # Ignorar las etiquetas, usar solo las entradas\n",
    "        reconstructed_batch = autoencoder(batch.to(device)).detach().cpu().numpy()\n",
    "        batch = batch.cpu().numpy()\n",
    "        reconstruction_errors.extend(\n",
    "            # np.mean(np.square(batch - reconstructed_batch), axis=(1, 2))\n",
    "            np.square(batch - reconstructed_batch)\n",
    "        )\n",
    "\n",
    "    return anomaly_limits(reconstruction_errors, percentile, axis=(0, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_channels_thresholds_autoencoder_last(percentile, autoencoder, df_normalized, window_size, batch_size, device):\n",
    "    steps_per_epoch = (len(df_normalized) - window_size) // batch_size\n",
    "\n",
    "    # Umbral basado en el percentil 95 del error\n",
    "    train_gen = sequence_generator_last_event(df_normalized.values, window_size, batch_size)\n",
    "    reconstruction_errors = []\n",
    "\n",
    "    # Barra de progreso para el cálculo de reconstruction_errors\n",
    "    for _ in tqdm(range(steps_per_epoch), desc=\"Calculando errores de reconstrucción\"):\n",
    "        batch_inputs, batch_targets = next(train_gen)\n",
    "        batch_inputs = batch_inputs.to(device)\n",
    "\n",
    "        reconstructed_batch = autoencoder(batch_inputs).detach().cpu().numpy()\n",
    "        batch_targets = batch_targets.cpu().numpy()\n",
    "\n",
    "        reconstruction_errors.extend(\n",
    "            # np.mean(np.square(batch - reconstructed_batch), axis=(1, 2))\n",
    "            np.square(batch_targets - reconstructed_batch)\n",
    "        )\n",
    "    return anomaly_limits(reconstruction_errors, percentile, axis=(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_channels_thresholds_vae_full(percentile, autoencoder, df_normalized, window_size, batch_size, device):\n",
    "    steps_per_epoch = (len(df_normalized) - window_size) // batch_size\n",
    "\n",
    "    # Umbral basado en el percentil 95 del error\n",
    "    train_gen = sequence_generator(df_normalized.values, window_size, batch_size)\n",
    "    reconstruction_errors = []\n",
    "\n",
    "    # Barra de progreso para el cálculo de reconstruction_errors\n",
    "    for _ in tqdm(range(steps_per_epoch), desc=\"Calculando errores de reconstrucción\"):\n",
    "        batch, _ = next(train_gen)  # Ignorar las etiquetas, usar solo las entradas\n",
    "        reconstructed_batch, _, _ = autoencoder(batch.to(device))\n",
    "        reconstructed_batch = reconstructed_batch.detach().cpu().numpy()\n",
    "        batch = batch.cpu().numpy()\n",
    "        reconstruction_errors.extend(\n",
    "            # np.mean(np.square(batch - reconstructed_batch), axis=(1, 2))\n",
    "            np.square(batch - reconstructed_batch)\n",
    "        )\n",
    "\n",
    "    return anomaly_limits(reconstruction_errors, percentile, axis=(0, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_channels_thresholds_vae_last(percentile, autoencoder, df_normalized, window_size, batch_size, device):\n",
    "    steps_per_epoch = (len(df_normalized) - window_size) // batch_size\n",
    "\n",
    "    # Umbral basado en el percentil 95 del error\n",
    "    train_gen = sequence_generator_last_event(df_normalized.values, window_size, batch_size)\n",
    "    reconstruction_errors = []\n",
    "\n",
    "    # Barra de progreso para el cálculo de reconstruction_errors\n",
    "    for _ in tqdm(range(steps_per_epoch), desc=\"Calculando errores de reconstrucción\"):\n",
    "        batch_inputs, batch_targets = next(train_gen)\n",
    "        batch_inputs = batch_inputs.to(device)\n",
    "\n",
    "        reconstructed_batch, _, _ = autoencoder(batch_inputs)\n",
    "        reconstructed_batch = reconstructed_batch.detach().cpu().numpy()\n",
    "\n",
    "        reconstruction_errors.extend(\n",
    "            # np.mean(np.square(batch - reconstructed_batch), axis=(1, 2))\n",
    "            np.square(batch_targets - reconstructed_batch)\n",
    "        )\n",
    "\n",
    "    return anomaly_limits(reconstruction_errors, percentile, axis=(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_channels_thresholds(model_type, percentile, autoencoder, df_normalized, window_size, batch_size, device):\n",
    "    if model_type == \"AutoEncoderFullWindow\":\n",
    "        return calculate_channels_thresholds_autoencoder_full(percentile, autoencoder, df_normalized, window_size, batch_size, device)\n",
    "    elif model_type == \"AutoEncoderLastEvent\":\n",
    "        return calculate_channels_thresholds_autoencoder_last(percentile, autoencoder, df_normalized, window_size, batch_size, device)\n",
    "    elif model_type == \"VariationalAutoencoderFullWindow\":\n",
    "        return calculate_channels_thresholds_vae_full(percentile, autoencoder, df_normalized, window_size, batch_size, device)\n",
    "    else:\n",
    "        return calculate_channels_thresholds_vae_last(percentile, autoencoder, df_normalized, window_size, batch_size, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(RESULT_PATH):\n",
    "    os.remove(RESULT_PATH)\n",
    "\n",
    "results = pd.DataFrame(columns=['Precision', 'Recall', 'F0.5', 'tp', 'fp', 'fn', 'tnt', 'nt', 'tnrt', \n",
    "                                'Training start', 'Training end', 'Test start', 'Test end',\n",
    "                                '#ESA Anomalies train', '#Predicted Anomalies train',\n",
    "                                '#ESA Anomalies test', '#Predicted Anomalies test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if os.path.exists(RESULT_PATH):\n",
    "#     results = pd.read_csv(RESULT_PATH)\n",
    "#     START_DATE = pd.to_datetime(\"2001-05-01\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_periods = calculate_period_months(START_DATE, END_DATE) - \\\n",
    "    MONTHS_TO_TRAIN - MONTHS_TO_TEST + 1\n",
    "\n",
    "for period in range(num_periods):\n",
    "    start_date_train = sum_months_to_date(START_DATE, period)\n",
    "    end_date_train = sum_months_to_date(start_date_train, MONTHS_TO_TRAIN)\n",
    "    start_date_test = end_date_train\n",
    "    end_date_test = sum_months_to_date(start_date_test, MONTHS_TO_TEST)\n",
    "    print(f\"PERIOD {period+1}/{num_periods} - Start train: {start_date_train.strftime('%Y-%m-%d')} - Start val: {start_date_test.strftime('%Y-%m-%d')} - End val: {end_date_test.strftime('%Y-%m-%d')}\")\n",
    "    row = {'Training start': start_date_train,\n",
    "           'Training end': end_date_train,\n",
    "           'Test start': start_date_test, \n",
    "           'Test end': end_date_test}\n",
    "\n",
    "\n",
    "    ### ********** TRAINING ********** ###\n",
    "    print(\"* Preprocessing train data\")\n",
    "    scaler = MinMaxScaler()\n",
    "    train_data = data[(start_date_train <= data.index) & (data.index <= end_date_train)]\n",
    "    train_data_normalized = scaler.fit_transform(train_data)\n",
    "    train_df_normalized = pd.DataFrame(train_data_normalized, index=train_data.index, columns=train_data.columns)\n",
    "\n",
    "    print(\"* Training model\")\n",
    "    model = train_model(MODEL_TYPE, train_df_normalized, EPOCHS, WINDOW_SIZE, BATCH_SIZE, LEARNING_RATE, device)\n",
    "\n",
    "    print(\"* Calculating threshold\")\n",
    "    threshold_list = calculate_channels_thresholds(MODEL_TYPE,\n",
    "                                                   PERCENTILE,\n",
    "                                                   model,\n",
    "                                                   train_df_normalized,\n",
    "                                                   WINDOW_SIZE,\n",
    "                                                   BATCH_SIZE,\n",
    "                                                   device)\n",
    "    ### ****************************** ###\n",
    "\n",
    "\n",
    "    ### ****** TRAINING METRICS ****** ###\n",
    "    print(\"* Calculating predicted training number of anomalies\")\n",
    "    train_prediction = model.predict(threshold_list, train_df_normalized, WINDOW_SIZE, BATCH_SIZE, device)\n",
    "    train_anomalies = format_anomalies(train_prediction)\n",
    "    row['#Predicted Anomalies train'] = len(train_anomalies)\n",
    "\n",
    "    print(\"* Calculating ESA training number of anomalies\")\n",
    "    esa_anomalies_train = filter_esa_anomalies(esa_anomalies, start_date_train, end_date_train)\n",
    "    row['#ESA Anomalies train'] = len(esa_anomalies_train)\n",
    "    ### ****************************** ###\n",
    "\n",
    "\n",
    "    ### ********* INFERENCE ********** ###\n",
    "    print(\"* Preprocessing test data\")\n",
    "    test_data = data[(start_date_test <= data.index) & (data.index <= end_date_test)]\n",
    "    test_data_normalized = scaler.transform(test_data)\n",
    "    test_df_normalized = pd.DataFrame(test_data_normalized, index=test_data.index, columns=test_data.columns)\n",
    "    \n",
    "    print(\"* Inference\")\n",
    "    test_prediction = model.predict(threshold_list, test_df_normalized, WINDOW_SIZE, BATCH_SIZE, device)\n",
    "    test_anomalies = format_anomalies(test_prediction)\n",
    "    row['#Predicted Anomalies test'] = len(test_anomalies)\n",
    "\n",
    "    print(\"* Calculating ESA test number of anomalies\")\n",
    "    esa_anomalies_test = filter_esa_anomalies(esa_anomalies, start_date_test, end_date_test)\n",
    "    row['#ESA Anomalies test'] = len(esa_anomalies_test)\n",
    "    ### ****************************** ###\n",
    "\n",
    "\n",
    "    ### ********** METRICS *********** ###\n",
    "    print(\"* Calculating metrics\")\n",
    "    scores_calculator = ESAScores(betas=0.5, full_range=(start_date_test, end_date_test)) \n",
    "    anomalies_list = get_anomalies_list(test_prediction)\n",
    "    scores_metrics = scores_calculator.score(esa_anomalies_test, anomalies_list)\n",
    "    row['Precision'], row['Recall'], row['F0.5'] = scores_metrics[\"EW_precision\"], scores_metrics[\"EW_recall\"], scores_metrics[\"EW_F_0.50\"]\n",
    "    row['tp'], row['fp'], row['fn'] = scores_metrics[\"tp\"], scores_metrics[\"fp\"], scores_metrics[\"fn\"]\n",
    "    row['tnt'], row['nt'], row['tnrt'] = scores_metrics[\"tnt\"], scores_metrics[\"nt\"], scores_metrics[\"tnrt\"]\n",
    "    ### ****************************** ###\n",
    "\n",
    "\n",
    "    ### ******** SAVE RESULTS ******** ###\n",
    "    results = pd.concat([results, pd.DataFrame([row])], ignore_index=True) if len(results) > 0 else pd.DataFrame([row])\n",
    "    # if period % 5 == 0 or period == num_periods - 1:\n",
    "    if period % 1 == 0 or period == num_periods - 1:\n",
    "        print(\"* Saving result:\", RESULT_PATH)\n",
    "        results.to_csv(RESULT_PATH, index=False)\n",
    "    print()\n",
    "    ### ****************************** ###\n",
    "\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate final metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "tp = results['tp'].sum()\n",
    "fp = results['fp'].sum()\n",
    "fn = results['fn'].sum()\n",
    "tnt = results['tnt'].sum()\n",
    "nt = results['nt'].sum()\n",
    "tnrt = tnt / nt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision = precision_corrected_score(tp, fp, tnrt)\n",
    "recall = recall_score(tp, fn)\n",
    "f05 = f05_score(precision, recall)\n",
    "\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F0.5: {f05:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear el plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(results[\"Test start\"], results[\"Precision\"], label=\"Precision\", marker=\"o\", color=\"blue\")\n",
    "plt.plot(results[\"Test start\"], results[\"Recall\"], label=\"Recall\", marker=\"s\", color=\"green\")\n",
    "plt.plot(results[\"Test start\"], results[\"F0.5\"], label=\"F0.5\", marker=\"^\", color=\"orange\")\n",
    "\n",
    "# Configurar el plot\n",
    "plt.title(\"Evolución de Precision, Recall y F0.5 a lo largo de los tests\")\n",
    "plt.xlabel(\"Fecha de Test\")\n",
    "plt.ylabel(\"Valor\")\n",
    "plt.legend()\n",
    "plt.grid(True, linestyle=\"--\", alpha=0.6)\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "\n",
    "# Mostrar el plot\n",
    "graphic_save_path = f\"../graphics/multiphases_training/ALL_{EXPERIMENT_NAME}.jpg\"\n",
    "plt.savefig(graphic_save_path, dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear un subplot con 3 gráficos diferentes dentro del mismo plot\n",
    "fig, axes = plt.subplots(3, 1, figsize=(10, 12), sharex=True)\n",
    "\n",
    "# Precision\n",
    "axes[0].plot(results[\"Test start\"], results[\"Precision\"], marker=\"o\", color=\"blue\", label=\"Precision\")\n",
    "axes[0].set_title(\"Precision\")\n",
    "axes[0].set_ylabel(\"Valor\")\n",
    "axes[0].grid(True, linestyle=\"--\", alpha=0.6)\n",
    "axes[0].legend()\n",
    "\n",
    "# Recall\n",
    "axes[1].plot(results[\"Test start\"], results[\"Recall\"], marker=\"s\", color=\"green\", label=\"Recall\")\n",
    "axes[1].set_title(\"Recall\")\n",
    "axes[1].set_ylabel(\"Valor\")\n",
    "axes[1].grid(True, linestyle=\"--\", alpha=0.6)\n",
    "axes[1].legend()\n",
    "\n",
    "# F0.5\n",
    "axes[2].plot(results[\"Test start\"], results[\"F0.5\"], marker=\"^\", color=\"orange\", label=\"F0.5\")\n",
    "axes[2].set_title(\"F0.5\")\n",
    "axes[2].set_ylabel(\"Valor\")\n",
    "axes[2].set_xlabel(\"Fecha de Test\")\n",
    "axes[2].grid(True, linestyle=\"--\", alpha=0.6)\n",
    "axes[2].legend()\n",
    "\n",
    "# Ajustar el diseño del subplot\n",
    "plt.tight_layout()\n",
    "graphic_save_path = f\"../graphics/multiphases_training/SEPARATED_{EXPERIMENT_NAME}.jpg\"\n",
    "plt.savefig(graphic_save_path, dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Store metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "import shutil\n",
    "import os\n",
    "\n",
    "wandb_dir = os.path.join(os.getcwd(), \"wandb\")\n",
    "try:\n",
    "    if os.path.exists(wandb_dir):\n",
    "        shutil.rmtree(wandb_dir)\n",
    "        print(\"Local wandb folder has been removed.\")\n",
    "    else:\n",
    "        print(\"Local wandb folder not found.\")\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_name = EXPERIMENT_NAME.replace(\"VariationalAutoencoderFullWindow\", \"VAEFull\").replace(\"VariationalAutoencoderLastEvent\", \"VAELast\").replace(\"AutoEncoderFullWindow\", \"AEFull\").replace(\"AutoEncoderLastEvent\", \"AELast\")\n",
    "run_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run = wandb.init(\n",
    "    # set the wandb project where this run will be logged\n",
    "    project=\"MET-ESA\",\n",
    "\n",
    "    id=run_name,\n",
    "    name=run_name,\n",
    "\n",
    "    # track hyperparameters and run metadata\n",
    "    config={\n",
    "        \"experiment_type\": \"multiphases_training\",\n",
    "        \"mission\": MISSION,\n",
    "        \"model_type\": MODEL_TYPE,\n",
    "        \"timestamp\": timestamp,\n",
    "        \"channels\": CHANNELS,\n",
    "        \"start_date\": START_DATE.strftime('%Y-%m-%d'),\n",
    "        \"end_date\": END_DATE.strftime('%Y-%m-%d'),\n",
    "        \"months_to_train\": MONTHS_TO_TRAIN,\n",
    "        \"months_to_test\": MONTHS_TO_TEST,\n",
    "        \"window_size\": WINDOW_SIZE,\n",
    "        \"percentile\": PERCENTILE,\n",
    "        \"epochs\": EPOCHS,\n",
    "        \"learning_rate\": LEARNING_RATE,\n",
    "    },\n",
    "    allow_val_change=True,\n",
    "    reinit=True,\n",
    "\n",
    "    resume=\"allow\",\n",
    "    settings=wandb.Settings(init_timeout=300)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, row in results.iterrows():\n",
    "    wandb.log(row.to_dict(), step=i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "table = wandb.Table(columns= [\"model_name\", \"precision\", \"recall\", \"f0.5\"])\n",
    "table.add_data(EXPERIMENT_NAME, precision, recall, f05)\n",
    "wandb.log({\"metrics\": table})\n",
    "\n",
    "wandb.log({\"general_precision\": precision, \"general_recall\": recall, \"general_f0.5\": f05})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.finish();"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
